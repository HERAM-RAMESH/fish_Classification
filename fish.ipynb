{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b200b2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f313dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a01d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (3.11.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: rich in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\heram ramesh\\anaconda3_new\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras numpy pandas matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2244aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd5d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras will automatically read sub folder as class label\n",
    "test_path  = r\"C:\\Users\\YourName\\Desktop\\fish classification\\dataset\\test\"\n",
    "train_path = r\"C:\\Users\\YourName\\Desktop\\fish classification\\dataset\\train\"\n",
    "val_path   = r\"C:\\Users\\YourName\\Desktop\\fish classification\\dataset\\val\"\n",
    "\n",
    "\n",
    "\n",
    "img_size = (224, 224)   # resize all images to 224x224\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317a8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,      # normalize pixel values to [0, 1]\n",
    "    rotation_range=20,   # rotate images\n",
    "    zoom_range=0.2,      # zoom in/out\n",
    "    horizontal_flip=True,# flip images horizontally\n",
    "    validation_split=0.2 # reserve 20% for validation\n",
    ")\n",
    "\n",
    "# Validation data without augmentation\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280981fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# load dataset from folder\n",
    "\n",
    "train_path = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\train\"\n",
    "val_path   = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\val\"\n",
    "test_path  = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\test\"\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f85bc00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,379</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,170,379\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,379</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,170,379\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 1s/step - accuracy: 0.4055 - loss: 1.7070 - val_accuracy: 0.6282 - val_loss: 1.0793\n",
      "Epoch 2/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 950ms/step - accuracy: 0.5921 - loss: 1.1529 - val_accuracy: 0.7390 - val_loss: 0.7759\n",
      "Epoch 3/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 1s/step - accuracy: 0.6652 - loss: 0.9105 - val_accuracy: 0.7976 - val_loss: 0.6866\n",
      "Epoch 4/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 919ms/step - accuracy: 0.7320 - loss: 0.7548 - val_accuracy: 0.8764 - val_loss: 0.4578\n",
      "Epoch 5/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 696ms/step - accuracy: 0.7778 - loss: 0.6470 - val_accuracy: 0.9038 - val_loss: 0.3440\n",
      "Epoch 6/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 715ms/step - accuracy: 0.8003 - loss: 0.5717 - val_accuracy: 0.8013 - val_loss: 0.6862\n",
      "Epoch 7/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 776ms/step - accuracy: 0.8127 - loss: 0.5242 - val_accuracy: 0.9441 - val_loss: 0.2350\n",
      "Epoch 8/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 794ms/step - accuracy: 0.8339 - loss: 0.4833 - val_accuracy: 0.9560 - val_loss: 0.2113\n",
      "Epoch 9/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 815ms/step - accuracy: 0.8554 - loss: 0.4245 - val_accuracy: 0.9359 - val_loss: 0.2260\n",
      "Epoch 10/10\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 814ms/step - accuracy: 0.8691 - loss: 0.3833 - val_accuracy: 0.9542 - val_loss: 0.2149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Number of classes (from your dataset)\n",
    "num_classes = train_data.num_classes  \n",
    "\n",
    "# Build CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"cnn_fish_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1c6050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1048s\u001b[0m 5s/step - accuracy: 0.5425 - loss: 1.4114 - val_accuracy: 0.8892 - val_loss: 0.6883\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1038s\u001b[0m 5s/step - accuracy: 0.7643 - loss: 0.7605 - val_accuracy: 0.9377 - val_loss: 0.4055\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1030s\u001b[0m 5s/step - accuracy: 0.8379 - loss: 0.5529 - val_accuracy: 0.9469 - val_loss: 0.2836\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1063s\u001b[0m 5s/step - accuracy: 0.8744 - loss: 0.4431 - val_accuracy: 0.9588 - val_loss: 0.2230\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1005s\u001b[0m 5s/step - accuracy: 0.9018 - loss: 0.3598 - val_accuracy: 0.9744 - val_loss: 0.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load base VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base layers\n",
    "\n",
    "# Add custom layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "model_vgg16 = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model_vgg16.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_vgg16.save(\"model_vgg16.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9bcfa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 3s/step - accuracy: 0.1698 - loss: 2.3815 - val_accuracy: 0.1712 - val_loss: 2.3195\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 3s/step - accuracy: 0.1759 - loss: 2.3335 - val_accuracy: 0.1712 - val_loss: 2.2659\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 3s/step - accuracy: 0.1761 - loss: 2.3024 - val_accuracy: 0.1712 - val_loss: 2.2616\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m584s\u001b[0m 3s/step - accuracy: 0.1762 - loss: 2.2827 - val_accuracy: 0.1712 - val_loss: 2.2618\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 3s/step - accuracy: 0.1761 - loss: 2.2718 - val_accuracy: 0.1712 - val_loss: 2.2077\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 3s/step - accuracy: 0.1632 - loss: 2.2320\n",
      "ResNet50 Test Accuracy: 0.1632, Test Loss: 2.2320\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load base ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base layers\n",
    "\n",
    "# Add custom layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "model_resnet50 = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model_resnet50.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history_resnet50 = model_resnet50.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Save model (using .keras format to avoid warning)\n",
    "model_resnet50.save(\"model_resnet50.keras\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model_resnet50.evaluate(test_data)\n",
    "print(f\"ResNet50 Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07908a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 941ms/step - accuracy: 0.6940 - loss: 0.9761 - val_accuracy: 0.9643 - val_loss: 0.1467\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 1s/step - accuracy: 0.8882 - loss: 0.3298 - val_accuracy: 0.9872 - val_loss: 0.0503\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 944ms/step - accuracy: 0.9251 - loss: 0.2227 - val_accuracy: 0.9872 - val_loss: 0.0451\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 897ms/step - accuracy: 0.9399 - loss: 0.1685 - val_accuracy: 0.9908 - val_loss: 0.0341\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 904ms/step - accuracy: 0.9520 - loss: 0.1446 - val_accuracy: 0.9936 - val_loss: 0.0215\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 565ms/step - accuracy: 0.9950 - loss: 0.0182\n",
      "MobileNet Test Accuracy: 0.9950, Test Loss: 0.0182\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Use MobileNet-specific preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Reload datasets with correct preprocessing\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load base MobileNet\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base layers\n",
    "\n",
    "# Add custom layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "model_mobilenet = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model_mobilenet.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Train (initial frozen layers)\n",
    "history_mobilenet = model_mobilenet.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_mobilenet.save(\"model_mobilenet.keras\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model_mobilenet.evaluate(test_data)\n",
    "print(f\"MobileNet Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6f93ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 2s/step - accuracy: 0.6493 - loss: 1.0428 - val_accuracy: 0.9304 - val_loss: 0.2969\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 4s/step - accuracy: 0.7955 - loss: 0.6032 - val_accuracy: 0.9496 - val_loss: 0.1916\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 1s/step - accuracy: 0.8357 - loss: 0.4707 - val_accuracy: 0.9432 - val_loss: 0.1703\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 1s/step - accuracy: 0.8501 - loss: 0.4231 - val_accuracy: 0.9661 - val_loss: 0.1141\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 2s/step - accuracy: 0.8700 - loss: 0.3625 - val_accuracy: 0.9780 - val_loss: 0.0984\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.9824 - loss: 0.0741\n",
      "InceptionV3 Test Accuracy: 0.9824, Test Loss: 0.0741\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# InceptionV3-specific preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Reload datasets with RGB forced\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),   # InceptionV3 default is 299x299, but 224x224 works fine\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Load base InceptionV3\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # freeze pretrained layers\n",
    "\n",
    "# Add custom classification head\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "model_inceptionv3 = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model_inceptionv3.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history_inceptionv3 = model_inceptionv3.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_inceptionv3.save(\"model_inceptionv3.keras\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model_inceptionv3.evaluate(test_data)\n",
    "print(f\"InceptionV3 Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5c96c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct dataset paths\n",
    "train_path = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\train\"\n",
    "val_path   = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\val\"\n",
    "test_path  = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89840efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 3s/step - accuracy: 0.7971 - loss: 0.6561 - val_accuracy: 0.9835 - val_loss: 0.0732\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 2s/step - accuracy: 0.9404 - loss: 0.1851 - val_accuracy: 0.9936 - val_loss: 0.0268\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 2s/step - accuracy: 0.9505 - loss: 0.1526 - val_accuracy: 0.9881 - val_loss: 0.0496\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 2s/step - accuracy: 0.9643 - loss: 0.1091 - val_accuracy: 0.9945 - val_loss: 0.0157\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.9759 - loss: 0.0767 - val_accuracy: 0.9954 - val_loss: 0.0210\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.9956 - loss: 0.0197\n",
      "EfficientNetV2B0 Test Accuracy: 0.9956, Test Loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generators with EfficientNetV2 preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_path, target_size=(224, 224), batch_size=batch_size, class_mode=\"categorical\"\n",
    ")\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_path, target_size=(224, 224), batch_size=batch_size, class_mode=\"categorical\"\n",
    ")\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_path, target_size=(224, 224), batch_size=batch_size, class_mode=\"categorical\", shuffle=False\n",
    ")\n",
    "\n",
    "# Load EfficientNetV2B0 with pretrained weights\n",
    "base_model = EfficientNetV2B0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # freeze pretrained layers\n",
    "\n",
    "# Custom head\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(train_data.num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model_efficientnetv2b0 = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model_efficientnetv2b0.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                               loss=\"categorical_crossentropy\",\n",
    "                               metrics=[\"accuracy\"])\n",
    "\n",
    "# Train\n",
    "history_efficientnetv2b0 = model_efficientnetv2b0.fit(\n",
    "    train_data, validation_data=val_data, epochs=5\n",
    ")\n",
    "\n",
    "# Save\n",
    "model_efficientnetv2b0.save(\"model_efficientnetv2b0.keras\")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model_efficientnetv2b0.evaluate(test_data)\n",
    "print(f\"EfficientNetV2B0 Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9827f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training VGG16...\n",
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1115s\u001b[0m 6s/step - accuracy: 0.5700 - loss: 2.4812 - val_accuracy: 0.8773 - val_loss: 0.4380\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1778s\u001b[0m 9s/step - accuracy: 0.8156 - loss: 0.5781 - val_accuracy: 0.9551 - val_loss: 0.2362\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2914s\u001b[0m 15s/step - accuracy: 0.8858 - loss: 0.3787 - val_accuracy: 0.9634 - val_loss: 0.1631\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1787s\u001b[0m 9s/step - accuracy: 0.9147 - loss: 0.2649 - val_accuracy: 0.9725 - val_loss: 0.1427\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 6s/step - accuracy: 0.9406 - loss: 0.1838 - val_accuracy: 0.9771 - val_loss: 0.1362\n",
      "✅ VGG16 Test Accuracy: 0.9859, Test Loss: 0.0661\n",
      "\n",
      "🚀 Training ResNet50...\n",
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 2s/step - accuracy: 0.7820 - loss: 0.7547 - val_accuracy: 0.9817 - val_loss: 0.0559\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 2s/step - accuracy: 0.9385 - loss: 0.1746 - val_accuracy: 0.9853 - val_loss: 0.0390\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 2s/step - accuracy: 0.9555 - loss: 0.1268 - val_accuracy: 0.9881 - val_loss: 0.0315\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 2s/step - accuracy: 0.9667 - loss: 0.0939 - val_accuracy: 0.9899 - val_loss: 0.0243\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 2s/step - accuracy: 0.9743 - loss: 0.0758 - val_accuracy: 0.9954 - val_loss: 0.0109\n",
      "✅ ResNet50 Test Accuracy: 0.9965, Test Loss: 0.0112\n",
      "\n",
      "🚀 Training MobileNet...\n",
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 550ms/step - accuracy: 0.7452 - loss: 0.7890 - val_accuracy: 0.9808 - val_loss: 0.0754\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 545ms/step - accuracy: 0.9417 - loss: 0.1727 - val_accuracy: 0.9927 - val_loss: 0.0253\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 2s/step - accuracy: 0.9610 - loss: 0.1134 - val_accuracy: 0.9927 - val_loss: 0.0258\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 499ms/step - accuracy: 0.9684 - loss: 0.0846 - val_accuracy: 0.9918 - val_loss: 0.0262\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 497ms/step - accuracy: 0.9764 - loss: 0.0682 - val_accuracy: 0.9954 - val_loss: 0.0197\n",
      "✅ MobileNet Test Accuracy: 0.9969, Test Loss: 0.0074\n",
      "\n",
      "🚀 Training InceptionV3...\n",
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - accuracy: 0.6432 - loss: 1.0384 - val_accuracy: 0.9469 - val_loss: 0.2669\n",
      "Epoch 2/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.8516 - loss: 0.4303 - val_accuracy: 0.9643 - val_loss: 0.1535\n",
      "Epoch 3/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - accuracy: 0.8839 - loss: 0.3238 - val_accuracy: 0.9762 - val_loss: 0.1082\n",
      "Epoch 4/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 1s/step - accuracy: 0.9168 - loss: 0.2352 - val_accuracy: 0.9689 - val_loss: 0.1364\n",
      "Epoch 5/5\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.9327 - loss: 0.1922 - val_accuracy: 0.9799 - val_loss: 0.0743\n",
      "✅ InceptionV3 Test Accuracy: 0.9871, Test Loss: 0.0500\n",
      "\n",
      "🚀 Training EfficientNetB0...\n",
      "Found 6225 images belonging to 11 classes.\n",
      "Found 1092 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 90\u001b[0m\n\u001b[0;32m     81\u001b[0m models_to_train \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     82\u001b[0m     (VGG16, vgg_pre, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG16\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     83\u001b[0m     (ResNet50, resnet_pre, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet50\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     (EfficientNetB0, efficientnet_pre, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEfficientNetB0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m ]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_model, pre_fn, name \u001b[38;5;129;01min\u001b[39;00m models_to_train:\n\u001b[1;32m---> 90\u001b[0m     m_name, acc, loss, hist \u001b[38;5;241m=\u001b[39m train_model(base_model, pre_fn, name, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     91\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend([m_name, acc, loss])\n\u001b[0;32m     92\u001b[0m     histories[m_name] \u001b[38;5;241m=\u001b[39m hist\n",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(base_model_class, preprocess_fn, model_name, epochs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🚀 Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m train_data, val_data, test_data \u001b[38;5;241m=\u001b[39m get_data(preprocess_fn)\n\u001b[1;32m---> 55\u001b[0m base_model \u001b[38;5;241m=\u001b[39m base_model_class(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     56\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# freeze base layers\u001b[39;00m\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m Flatten()(base_model\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[1;32mc:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:571\u001b[0m, in \u001b[0;36mEfficientNetB0\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[0;32m    556\u001b[0m     [\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.efficientnet.EfficientNetB0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    569\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnetb0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    570\u001b[0m ):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EfficientNet(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;241m224\u001b[39m,\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m    576\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    577\u001b[0m         include_top\u001b[38;5;241m=\u001b[39minclude_top,\n\u001b[0;32m    578\u001b[0m         weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m    579\u001b[0m         input_tensor\u001b[38;5;241m=\u001b[39minput_tensor,\n\u001b[0;32m    580\u001b[0m         input_shape\u001b[38;5;241m=\u001b[39minput_shape,\n\u001b[0;32m    581\u001b[0m         pooling\u001b[38;5;241m=\u001b[39mpooling,\n\u001b[0;32m    582\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    583\u001b[0m         classifier_activation\u001b[38;5;241m=\u001b[39mclassifier_activation,\n\u001b[0;32m    584\u001b[0m         weights_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    585\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:434\u001b[0m, in \u001b[0;36mEfficientNet\u001b[1;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, weights_name)\u001b[0m\n\u001b[0;32m    427\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;241m+\u001b[39m file_suffix\n\u001b[0;32m    428\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    429\u001b[0m         file_name,\n\u001b[0;32m    430\u001b[0m         BASE_WEIGHTS_PATH \u001b[38;5;241m+\u001b[39m file_name,\n\u001b[0;32m    431\u001b[0m         cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m         file_hash\u001b[38;5;241m=\u001b[39mfile_hash,\n\u001b[0;32m    433\u001b[0m     )\n\u001b[1;32m--> 434\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[1;32mc:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Heram Ramesh\\anaconda3_new\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:447\u001b[0m, in \u001b[0;36m_set_weights\u001b[1;34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[0m\n\u001b[0;32m    437\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    438\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping loading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to mismatch in shape for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    445\u001b[0m             )\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i]\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived saved weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         )\n\u001b[0;32m    454\u001b[0m     symbolic_weights[i]\u001b[38;5;241m.\u001b[39massign(weight_value)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinalize_state\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m symbolic_weights:\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNet, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_pre\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_pre\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_pre\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_pre\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# =============================\n",
    "# Dataset Paths\n",
    "# =============================\n",
    "train_path = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\train\"\n",
    "val_path   = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\val\"\n",
    "test_path  = r\"C:\\Users\\Heram Ramesh\\OneDrive\\Desktop\\fish classification\\fish_data\\images.cv_jzk6llhf18tm3k0kyttxz\\data\\test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# =============================\n",
    "# Helper: build dataloaders\n",
    "# =============================\n",
    "def get_data(preprocess_fn):\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
    "\n",
    "    train_data = train_datagen.flow_from_directory(\n",
    "        train_path, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', color_mode='rgb'\n",
    "    )\n",
    "    val_data = val_datagen.flow_from_directory(\n",
    "        val_path, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', color_mode='rgb'\n",
    "    )\n",
    "    test_data = test_datagen.flow_from_directory(\n",
    "        test_path, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', shuffle=False, color_mode='rgb'\n",
    "    )\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# =============================\n",
    "# Helper: build & train model\n",
    "# =============================\n",
    "def train_model(base_model_class, preprocess_fn, model_name, epochs=5):\n",
    "    print(f\"\\n🚀 Training {model_name}...\")\n",
    "    train_data, val_data, test_data = get_data(preprocess_fn)\n",
    "\n",
    "    base_model = base_model_class(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # freeze base layers\n",
    "\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(train_data, validation_data=val_data, epochs=epochs, verbose=1)\n",
    "    model.save(f\"{model_name}.keras\")\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_data, verbose=0)\n",
    "    print(f\"✅ {model_name} Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    return model_name, test_acc, test_loss, history\n",
    "\n",
    "# =============================\n",
    "# Train All 5 Models\n",
    "# =============================\n",
    "results = []\n",
    "histories = {}\n",
    "\n",
    "models_to_train = [\n",
    "    (VGG16, vgg_pre, \"VGG16\"),\n",
    "    (ResNet50, resnet_pre, \"ResNet50\"),\n",
    "    (MobileNet, mobilenet_pre, \"MobileNet\"),\n",
    "    (InceptionV3, inception_pre, \"InceptionV3\"),\n",
    "    (EfficientNetB0, efficientnet_pre, \"EfficientNetB0\")\n",
    "]\n",
    "\n",
    "for base_model, pre_fn, name in models_to_train:\n",
    "    m_name, acc, loss, hist = train_model(base_model, pre_fn, name, epochs=5)\n",
    "    results.append([m_name, acc, loss])\n",
    "    histories[m_name] = hist\n",
    "\n",
    "# =============================\n",
    "# Comparison Table\n",
    "# =============================\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"Test Accuracy\", \"Test Loss\"])\n",
    "print(\"\\n📊 Final Results:\\n\", df_results)\n",
    "\n",
    "# =============================\n",
    "# Plot Accuracy Curves\n",
    "# =============================\n",
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title(f\"{title} Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for model_name, hist in histories.items():\n",
    "    plot_history(hist, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
